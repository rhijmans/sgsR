---
title: "calculating"
output: rmarkdown::html_vignette
description: >
  Learn how to use calculate_* functions.
vignette: >
  %\VignetteIndexEntry{calculating}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r,warning=F,message=F,echo=FALSE,results=FALSE}
library(sgsR)
library(terra)

#--- Load mraster and access files ---#
r <- system.file("extdata", "wall_metrics.tif", package = "sgsR")

#--- load the mraster using the terra package ---#
mraster <- terra::rast(r)

a <- system.file("extdata", "roads.shp", package = "sgsR")

#--- load the access vector using the sf package ---#
access <- sf::st_read(a, quiet = TRUE)

#--- apply kmeans algorithm to metrics raster ---#
sraster <- strat_kmeans(mraster = mraster, 
                        nStrata = 4) # algorithm will plot output

#--- apply kmeans algorithm to metrics raster ---#
existing <- sample_srs(raster = mraster, # use sraster as input for sampling
                       nSamp = 200, # request 200 samples be taken
                       mindist = 100) # algorithm will plot output

```

Currently, there are 8 functions associated with the `calculate` verb in the `sgsR` package:

*   `calculate_representation()` - compare the representation of strata in existing sample

*   `calculate_distance()` - per pixel distance to the closest access vector

*   `calculate_pcomp()`- principal components on the input `mraster`

*   `calculate_sampsize()` - determines the appropriate sample sizes based on relative standard error thresholds

*   `calculate_allocation()` - sample allocation algorithm - proportional / optimal / equal sampling

*   `calculate_coobs()` - count of observations algorithm

*   `calculate_pop()` - population covariate statistics for latin hypercube sampling

*   `calculate_lhsOpt()` - optimal latin hypercube sampling paramters including sample number

`calculate_*` functions serve as the helper functions. In this section we outline and demonstrate how these functions can be used.

## `calculate_representation()` {#rep .unnumbered}

`calculate_representation()` function allows the users to verify how well the stratification is represented in their `existing` sample networks. Users input `sraster` and their `existing` samples to the `calculate_representation()` function, which will result in tabular and graphical (if `plot = TRUE`) output that compares strata coverage frequency and sampling frequency. 

```{r,warning=F,message=F}
#--- calculate representation ---#
calculate_representation(sraster = sraster, 
                         existing = existing, 
                         plot = TRUE)
```
The tabular output frames the frequency of the coverage for each strata (`srasterFreq`) and the sampling frequency within each strata (`sampleFreq`). The difference (`diffFreq`) between coverage frequency and sampling frequency determines whether the values are over-represented (positive numbers) or under-represented (negative numbers). This value also reflects the number of samples that are needed (`need`), in regards to adding or removing samples, to meet the number of samples necessary to be considered representative of the strata inputted in `sraster`. 

Performing the algorithm on a sample set derived using `sample_strat()` exhibits proportional sampling to strata coverage.

```{r,warning=F,message=F}
#--- stratified samples ---#
strat <- sample_strat(sraster = sraster,
                      nSamp = 200)

calculate_representation(sraster = sraster,
                         existing = strat,
                         plot = TRUE)
```

Presence of very small (negligible) differences between `srasterFreq` and `sampleFreq` is common. In these situations, it is important for the user to determine whether to add or remove the samples.  

## `calculate_distance` {#dist .unnumbered}

`calculate_distance()` function takes the input `raster` and `access` data and outputs the per pixel distance to the nearest access point. This function has a specific value for constraining the sampling protocols, such as the `sample_clhs()` function, where the output raster layer can be used as the `cost` for the constraint. The output raster consists of the input appended with the calculated distance layer (`dist2access`).

```{r,warning=F,message=F}
calculate_distance(raster = sraster, # input
                   access = access, # define access road network
                   plot = TRUE) # plot
```

## `calculate_pcomp` {.unnumbered}

`calculate_pcomp()` function takes `mraster` as the input and performs the principal component analysis. The number of components defined by the `nComp` parameter specifies the number of components that must be rasterized onto the output. 

```{r,warning=F,message=F}
calculate_pcomp(mraster = mraster, # input
                nComp = 3, # number of components to output
                plot = TRUE, # plot
                details = TRUE) # details about the principal component analysis appended

```

## `calculate_sampsize` {.unnumbered}

`calculate_sampsize()` function allows the user to determine the appropriate sample size using the relative standard error of the input metric. If the input `mraster` contains multiple layers, the sample sizes will be determined for all the layers. If `plot = TRUE` and `rse` is defined, a sequence of rse values will be visualized with the indicators and the values for the matching sample size.

```{r, warning = F}
#--- determine sample size based on relative standard error (rse) of 1% ---#
calculate_sampsize(mraster = mraster,
                   rse = 0.01)

```

```{r, warning = FALSE}
#--- change default threshold sequence values ---# 
#--- if increment and rse are not divisible the closest value will be taken ---#
p <- calculate_sampsize(mraster = mraster,
                   rse = 0.025,
                   start = 0.01,
                   end = 0.08,
                   increment = 0.01,
                   plot = TRUE)

p
```

## `calculate_allocation` {.unnumbered}

`calculate_allocation()` function calculates the total number of samples required to be allocated for the sampling, based on the total sample value (`nSamp`) and the input `sraster`. This function is used in a number of functions, including [`sample_strat`](#strat). Currently, there are three methods for allocations included: proportional (`prop`; default) allocation, optimal (`optim`) allocation, and equal (`equal`) allocation.

* Proportional - Samples are allocated based on the coverage area of the strata. This is the default allocation method.
* Optimal - Samples are allocated based on the variation within the strata.
* Equal - Same number of samples (`nSamp`) are allocated to each strata.

### Proportional allocation {#proportional .unnumbered}

```{r,warning=F,message=F}
#--- perform grid sampling ---#
calculate_allocation(sraster = sraster, 
                     nSamp = 200)
```

```{r,warning=F,message=F}
#--- calculate existing samples to include ---#
e.sr <- extract_strata(sraster = sraster, 
                       existing = existing)

calculate_allocation(sraster = sraster, 
                     nSamp = 200, 
                     existing = e.sr)
```

Notice that some of the values under `total` from the result above is negative. The negative value indicates that the `existing` samples over represent those strata and that some of the samples must be removed to prevent over-representation. The values in the details under the `$total` indicates the number of samples that ought to be added or removed. 

### Optimal Allocation {#optimal .unnumbered}

Optimal allocation method uses the variation within the strata metric to allocate samples. This means that in addition to providing and `sraster`, that a specific metric (`mraster`) must be provided to calculate variation to optimally allocate samples.

```{r, warning=F,message=F}
calculate_allocation(sraster = sraster, # stratified raster
                     nSamp = 200, # desired sample number
                     existing = e.sr, #existing samples
                     allocation = "optim", # optimal allocation
                     mraster = mraster$zq90, # metric raster
                     force = TRUE) # force nSamp number

```

### Equal allocation {#equal .unnumbered}
There might be situations where the user might want to have the same number of samples allocated to each strata. In these situations, it is ideal to use `allocation = equal`. In this situation, `nSamp` refers to the total number of samples per strata, instead of the overall total number of samples. 

```{r}
calculate_allocation(sraster = sraster, # stratified raster
                     nSamp = 20, # desired sample number
                     allocation = "equal") # optimal allocation
```
The code in the demonstration above yields a total of 80 samples (20 `nSamp` for each of the 4 strata in `sraster`).

## Sample evaluation algorithms {#sampeval .unnumbered}

The following algorithms were initially developed by Dr. Brendan Malone from the University of Sydney. Dr. Brendan Malone and his colleagues graciously supplied an in depth description of the functionality of these algorithms, which were originally developed to improve soil sampling strategies, in their paper. These functions were modified and implemented to be used for structurally guided sampling approaches. Many thanks to Dr. Malone for his excellent collaboration and being a proponent of open source algorithms.

Please consult the original reference, for these scripts and ideas, as their paper holds extremely helpful and valuable information to understand their sampling rationale.

_Malone BP, Minansy B, Brungard C. 2019. Some methods to improve the utility of conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451_ 

### `calculate_coobs` {#coobs .unnumbered}

`calculate_coobs()` function performs the COunt of OBServations (coobs) algorithm using `existing` sample data and `mraster` covariates. This algorithm helps the users understand how the `existing` sample data set is distributed among the landscape in relation to the `mraster` covariates. The output coobs raster can be used to constrain clhs sampling using the `sample_clhs()` function to the areas that are under-represented.


The coobs raster determines how many observations are similar in terms of the covariate space at every pixel. This function takes advantage of the parallel processing routines.

```{r,warning=F,message=F, eval = FALSE}
calculate_coobs(mraster = mraster, # input
                existing = existing, # existing samples
                cores = 4, # parallel cores to use
                details = TRUE, # provide details from algorithm output
                plot = TRUE, # plot
                filename = tempfile(fileext = ".tif")) # write output raster to tif
```

## Latin hypercube sampling evaluation algorithms {#lhseval .unnumbered}

The following 2 algorithms presents the means to maximize the effectiveness of the [latin hypercube sampling](#clhs) protocols. 

### `calculate_pop` {#lhspop .unnumbered}

`calculate_pop()` function calculates population level statistics of the `mraster` covariates that are being used, which includes calculating the principal components, quantile & covariate distributions, and Kullback-Leibler divergence testing. The outputs produced from this functions are required to use the `calculate_lhsOpt()` function described in the following section. Additionally, this algorithm can be preemptively used to calculate `matQ` and `MatCov`, two values that are used for the `sample_ahels()` function. 

```{r,warning=F,message=F, eval = FALSE}
#--- by default all statistical data are calculated ---#
calculate_pop(mraster = mraster) # input 
```

The output details the following:

* `$values` -  Pixel values from `mraster`

* `$pcaLoad` - PCA loadings

* `$matQ` - Quantile matrix

* `$matCov` - Covariate matrix

```{r,warning=F,message=F, eval = FALSE}
#--- statistical analyses can be chosen by setting their parameter to `FALSE` ---#
mat <- calculate_pop(mraster = mraster, # input
                     nQuant = 10) # desired number of quantiles

#--- use matrix output within sample ahels algorithm ---#
sample_ahels(mraster = mraster, 
             existing = existing, 
             nQuant = 10, 
             nSamp = 50,
             matCov = mat)
```

### `calculate_lhsOpt` {#lhsopt .unnumbered}

`calculate_lhsOpt()` function performs a bootstrapped latin hypercube sampling approach where population level analysis of `mraster` data is performed to determine the optimal latin hypercube sample size.

Using statistical data calculated using the `calculate_pop()` and varying sample sizes defined by `minSamp`, `maxSamp`, `step` and `rep`. Sampling protocols are conducted and statistical effectiveness of those sampling outcomes are evaluated to determine where sample size is minimized and statistical representation is maximized.

```{r,warning=F,message=F, eval = FALSE}
#--- calculate lhsPop details ---#
poplhs <- calculate_pop(mraster = mr)

calculate_lhsOpt(popLHS = poplhs)
```

```{r,warning=F,message=F, eval = FALSE}
calculate_lhsOpt(popLHS = poplhs, 
                 PCA = FALSE, 
                 iter = 200)
```
